import joblib
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, RandomizedSearchCV,KFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score
import xgboost as xgb

#fgas
def dividir_dados_em_conjuntos(df: pd.DataFrame):
    """
    Separa o DataFrame em features (X) e alvo (y), e depois divide
    em conjuntos de treino (60%), valida√ß√£o (20%) e teste (20%).
    Args:
        df (pd.DataFrame): O DataFrame limpo.
    Retorna:
        tuple: Uma tupla contendo X_train, X_val, X_test, y_train, y_val, y_test.
    """
    print("--- Iniciando Tarefa: Divis√£o dos Dados ---")

    X = df.drop('Produtividade_t_ha', axis=1)
    y = df['Produtividade_t_ha']

    # Primeiro split: 80% para treino+valida√ß√£o, 20% para teste
    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Segundo split: do conjunto de 80%, tira 25% para valida√ß√£o (0.25 * 0.8 = 0.2 do total)
    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)

    print(f"Tamanho do treino: {len(X_train)} ({len(X_train)/len(df):.0%})")
    print(f"Tamanho da valida√ß√£o: {len(X_val)} ({len(X_val)/len(df):.0%})")
    print(f"Tamanho do teste: {len(X_test)} ({len(X_test)/len(df):.0%})")

    return X_train, X_val, X_test, y_train, y_val, y_test


X_train, X_val, X_test, y_train, y_val, y_test = dividir_dados_em_conjuntos(df)

def criar_e_aplicar_preprocessamento(X_train, X_val, X_test):
    """
    Cria um pipeline de pr√©-processamento que normaliza dados num√©ricos e
    codifica dados categ√≥ricos. Treina o pipeline com os dados de treino e
    o aplica a todos os conjuntos.
    Args:
        X_train, X_val, X_test: DataFrames de features.
    Retorna:
        tuple: Contendo os conjuntos de features processados e o pipeline treinado.
    """
    print("--- Iniciando Tarefa: Pr√©-processamento Avan√ßado ---")

    # Identifica colunas num√©ricas e categ√≥ricas
    features_numericas = X_train.select_dtypes(include=np.number).columns.tolist()
    features_categoricas = X_train.select_dtypes(exclude=np.number).columns.tolist()

    # Cria os transformadores
    transformador_numerico = StandardScaler()
    transformador_categorico = OneHotEncoder(handle_unknown='ignore', sparse_output=False)

    # Cria o ColumnTransformer para aplicar transforma√ß√µes diferentes a colunas diferentes
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', transformador_numerico, features_numericas),
            ('cat', transformador_categorico, features_categoricas)
        ],
        remainder='passthrough'
    )

    # Treina o pipeline de pr√©-processamento APENAS com dados de treino
    preprocessor.fit(X_train)

    # Aplica a transforma√ß√£o a todos os conjuntos
    X_train_proc = preprocessor.transform(X_train)
    X_val_proc = preprocessor.transform(X_val)
    X_test_proc = preprocessor.transform(X_test)

    print("‚úÖ Dados normalizados e codificados.")

    return X_train_proc, X_val_proc, X_test_proc, preprocessor

X_train_proc, X_val_proc, X_test_proc, preprocessor = criar_e_aplicar_preprocessamento(X_train, X_val, X_test)

def ajustar_hiperparametros(X_train_proc, y_train):
    """
    Usa RandomizedSearchCV para encontrar a melhor combina√ß√£o de hiperpar√¢metros
    para o modelo RandomForestRegressor.
    Args:
        X_train_proc: Dados de treino processados.
        y_train: Alvo de treino.
    Retorna:
        dict: O dicion√°rio com os melhores par√¢metros encontrados.
    """
    print("--- Iniciando Tarefa: Ajuste de Hiperpar√¢metros ---")

    # Define o espa√ßo de par√¢metros para a busca
    param_dist = {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 20, 30, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2', 1.0]
    }

    rf = RandomForestRegressor(random_state=42, n_jobs=-1)

    # Configura a busca aleat√≥ria com valida√ß√£o cruzada
    random_search = RandomizedSearchCV(
        estimator=rf,
        param_distributions=param_dist,
        n_iter=20,  # N√∫mero de combina√ß√µes a testar
        cv=3,       # N√∫mero de folds da valida√ß√£o cruzada
        verbose=2,
        random_state=42,
        n_jobs=-1
    )

    # Executa a busca
    random_search.fit(X_train_proc, y_train)

    print(f"‚úÖ Melhores par√¢metros encontrados: {random_search.best_params_}")
    return random_search.best_params_

best_params = ajustar_hiperparametros(X_train_proc, y_train)


def treinar_e_avaliar_modelo_final(best_params, X_train_proc, y_train, X_val_proc, y_val, X_test_proc, y_test):
    """
    Treina o modelo final com os melhores hiperpar√¢metros no conjunto combinado
    de treino e valida√ß√£o. Depois, avalia no conjunto de teste.
    Args:
        best_params (dict): Melhores hiperpar√¢metros.
        (outros): Todos os conjuntos de dados.
    Retorna:
        object: O objeto do modelo final treinado.
    """
    print("--- Iniciando Tarefa: Treinamento e Avalia√ß√£o Final ---")

    # Combina dados de treino e valida√ß√£o para o treino final
    X_train_full = np.vstack((X_train_proc, X_val_proc))
    y_train_full = np.concatenate((y_train, y_val))

    # Cria o modelo final com os melhores par√¢metros
    modelo_final = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)

    # Treina o modelo final
    modelo_final.fit(X_train_full, y_train_full)
    print("‚úÖ Modelo final treinado com dados de treino + valida√ß√£o.")

    # Avalia no conjunto de teste (dados nunca vistos)
    y_pred = modelo_final.predict(X_test_proc)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))

    print("\n--- Avalia√ß√£o Final no Conjunto de Teste ---")
    print(f"MAE (Erro M√©dio Absoluto): {mae:.4f}")
    print(f"RMSE (Raiz do Erro Quadr√°tico M√©dio): {rmse:.4f}")

    return modelo_final

modelo_final = treinar_e_avaliar_modelo_final(best_params, X_train_proc, y_train, X_val_proc, y_val, X_test_proc, y_test)


def treinar_xgboost(X_train_proc, y_train, X_val_proc, y_val, X_test_proc, y_test):
    
    # 1. Busca de hiperpar√¢metros
    print("\nüîç Iniciando busca de hiperpar√¢metros para XGBoost...")
    
    param_dist = {
        'n_estimators': [100, 200, 300, 500],
        'max_depth': [3, 4, 5, 6, 7],
        'learning_rate': [0.001,0.0001,0.01]
    }

    model = xgb.XGBRegressor(
        objective='reg:squarederror',
        random_state=42,
        n_jobs=-1,
        early_stopping_rounds=10,
        tree_method='hist'
    )

    kfold = KFold(n_splits=5, shuffle=True, random_state=42)
    search = RandomizedSearchCV(
        model,
        param_dist,
        n_iter=20,
        cv=kfold,
        scoring='neg_mean_absolute_error',
        random_state=42
    )

    search.fit(X_train_proc, y_train, eval_set=[(X_val_proc, y_val)], verbose=False)
    
    best_params = search.best_params_
    print(f"\n‚úÖ Melhores par√¢metros encontrados:\n{best_params}")
    print(f"Melhor MAE: {-search.best_score_:.4f}")

    # 2. Treino do modelo final
    print("\nüèãÔ∏è Treinando modelo final XGBoost com todos os dados...")
    
    X_full = np.vstack((X_train_proc, X_val_proc))
    y_full = np.concatenate((y_train, y_val))

    modelo_final = xgb.XGBRegressor(
        **best_params,
        objective='reg:squarederror',
        random_state=42,
        n_jobs=-1
    )

    modelo_final.fit(X_full, y_full, eval_set=[(X_val_proc, y_val)], verbose=False)

    # 3. Avalia√ß√£o no conjunto de teste
    y_pred = modelo_final.predict(X_test_proc)

    print("\nüìä M√©tricas Finais no Teste:")
    print(f"MAE: {mean_absolute_error(y_test, y_pred):.4f}")
    print(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}")
    print(f"R¬≤: {r2_score(y_test, y_pred):.4f}")

    return modelo_final


modelo_xgb = treinar_xgboost(X_train_proc, y_train, X_val_proc, y_val, X_test_proc, y_test)

def salvar_artefatos(modelo, preprocessor):
    """
    Salva o modelo treinado e o pipeline de pr√©-processamento em arquivos.
    Args:
        modelo: O objeto do modelo treinado.
        preprocessor: O objeto do ColumnTransformer treinado.
    """
    print("--- Iniciando Tarefa: Salvando Artefatos ---")
    joblib.dump(modelo, 'modelo_final.joblib')
    joblib.dump(preprocessor, 'preprocessor.joblib')
    print("‚úÖ Modelo final e pipeline de pr√©-processamento salvos.")

salvar_artefatos(modelo_final, preprocessor)
